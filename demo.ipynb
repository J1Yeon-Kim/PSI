{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating 3D People in Scenes without People\n",
    "\n",
    "Here we give a frontend demo of how to generate body meshes in a scene without people. \n",
    "+ First, we use a pre-trained conditional VAE model to generate body meshes. Here we only show the one-stage model without scene loss. \n",
    "+ Second, we perform scene geometry-aware fitting.\n",
    "\n",
    "The code in this demo is slightly different from the code in other places. __To efficiently generate a large amount of body meshes for various scenes, we recommend to use the frontend sh scripts.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) loading dependencies, models and setup environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "\n",
    "import sys, os, glob\n",
    "import json\n",
    "import argparse\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "\n",
    "import open3d as o3d\n",
    "from pyntcloud import PyntCloud\n",
    "\n",
    "\n",
    "# proj_path = '/is/ps2/yzhang/workspaces/PSI-internal'\n",
    "proj_path = '/home/ryeon/project/psi'\n",
    "sys.path.append(proj_path)\n",
    "sys.path.append(proj_path+'/source')\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import init\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "import smplx\n",
    "from human_body_prior.tools.model_loader import load_vposer\n",
    "\n",
    "from cvae import HumanCVAES1, HumanCVAES2, ContinousRotReprDecoder\n",
    "\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import smplx\n",
    "from human_body_prior.tools.model_loader import load_vposer\n",
    "import chamfer_pytorch.dist_chamfer as ext\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We put some auxilary functions here, mainly for coordinate transform and file parsing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recover_global_T(x_batch, cam_intrisic, max_depth):\n",
    "    xt_batch = x_batch[:,:3]\n",
    "    xr_batch = x_batch[:,3:]\n",
    "\n",
    "    fx_batch = cam_intrisic[:,0,0]\n",
    "    fy_batch = cam_intrisic[:,1,1]\n",
    "    px_batch = cam_intrisic[:,0,2]\n",
    "    py_batch = cam_intrisic[:,1,2]\n",
    "    s_ = 1.0 / torch.max(px_batch, py_batch)\n",
    "\n",
    "    z = (xt_batch[:, 2]+1.0)/2.0 * max_depth\n",
    "\n",
    "    x = xt_batch[:,0] * z / s_ / fx_batch\n",
    "    y = xt_batch[:,1] * z / s_ / fy_batch\n",
    "    \n",
    "    xt_batch_recoverd = torch.stack([x,y,z],dim=-1)\n",
    "\n",
    "    return torch.cat([xt_batch_recoverd, xr_batch],dim=-1)\n",
    "\n",
    "\n",
    "\n",
    "def convert_to_3D_rot(x_batch):\n",
    "    xt = x_batch[:,:3]\n",
    "    xr = x_batch[:,3:9]\n",
    "    xb = x_batch[:,9:]\n",
    "\n",
    "    xr_mat = ContinousRotReprDecoder.decode(xr) # return [:,3,3]\n",
    "    xr_aa = ContinousRotReprDecoder.matrot2aa(xr_mat) # return [:,3]\n",
    "\n",
    "    return torch.cat([xt, xr_aa, xb], dim=-1)\n",
    "\n",
    "\n",
    "def body_params_encapsulate(x_body_rec, to_numpy=True, batched=False):\n",
    "    \n",
    "    if to_numpy:\n",
    "        x_body_rec_np = x_body_rec.detach().cpu().numpy()\n",
    "    else:\n",
    "        x_body_rec_np = x_body_rec\n",
    "        \n",
    "    \n",
    "    if batched:\n",
    "        body_params_batch_rec={}\n",
    "        body_params_batch_rec['transl'] = x_body_rec_np[:,:3]\n",
    "        body_params_batch_rec['global_orient'] = x_body_rec_np[:,3:6]\n",
    "        body_params_batch_rec['betas'] = x_body_rec_np[:,6:16]\n",
    "        body_params_batch_rec['body_pose'] = x_body_rec_np[:,16:48]\n",
    "        body_params_batch_rec['left_hand_pose'] = x_body_rec_np[:,48:60]\n",
    "        body_params_batch_rec['right_hand_pose'] = x_body_rec_np[:,60:]\n",
    "        \n",
    "        return body_params_batch_rec\n",
    "    \n",
    "    else:\n",
    "        n_batch = x_body_rec_np.shape[0]\n",
    "        rec_list = []\n",
    "\n",
    "        for b in range(n_batch):\n",
    "            body_params_batch_rec={}\n",
    "            body_params_batch_rec['transl'] = x_body_rec_np[b:b+1,:3]\n",
    "            body_params_batch_rec['global_orient'] = x_body_rec_np[b:b+1,3:6]\n",
    "            body_params_batch_rec['betas'] = x_body_rec_np[b:b+1,6:16]\n",
    "            body_params_batch_rec['body_pose'] = x_body_rec_np[b:b+1,16:48]\n",
    "            body_params_batch_rec['left_hand_pose'] = x_body_rec_np[b:b+1,48:60]\n",
    "            body_params_batch_rec['right_hand_pose'] = x_body_rec_np[b:b+1,60:]\n",
    "            rec_list.append(body_params_batch_rec)\n",
    "\n",
    "        return rec_list\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def data_preprocessing(img, modality, target_domain_size=[128, 128]):\n",
    "\n",
    "    \"\"\"\n",
    "    input:\n",
    "        - img (depthmap or semantic map): [height, width].\n",
    "        - modality: 'depth' or 'seg'\n",
    "    output:\n",
    "        canvas: with shape of target_domain_size, where the input is in the\n",
    "                center tightly, with shape target_domain_size\n",
    "        factor: the resizing factor\n",
    "    \"\"\"\n",
    "\n",
    "    # prepare the canvas\n",
    "    img_shape_o = img.shape\n",
    "    canvas = torch.zeros([1,1]+target_domain_size, dtype=torch.float32,\n",
    "                         device=torch.device(\"cuda\"))\n",
    "\n",
    "\n",
    "    # filter out unavailable values\n",
    "    if modality == 'depth':\n",
    "        img[img>6.0]=6.0\n",
    "\n",
    "    if modality == 'seg':\n",
    "        img[img>41] = 41\n",
    "\n",
    "\n",
    "\n",
    "    ## rescale to [-1,1]\n",
    "    max_val = torch.max(img)\n",
    "    _img = 2* img / max_val - 1.0\n",
    "\n",
    "    ## put _img to the canvas\n",
    "    if img_shape_o[0]>= img_shape_o[1]:\n",
    "        factor = float(target_domain_size[0]) / img_shape_o[0]\n",
    "        target_height = target_domain_size[0]\n",
    "        target_width = int(img_shape_o[1] * factor) //2 *2 \n",
    "\n",
    "        # for depth map we use bilinear interpolation in resizing\n",
    "        # for segmentation map we use bilinear interpolation as well.\n",
    "        # note that float semantic label is not real in practice, but\n",
    "        # helpful in our work\n",
    "        target_size = [target_height, target_width]\n",
    "\n",
    "        _img = _img.view(1,1,img_shape_o[0],img_shape_o[1])\n",
    "        img_resize = F.interpolate(_img, size=target_size, mode='bilinear',\n",
    "                                    align_corners=False)\n",
    "\n",
    "        na = target_width\n",
    "        nb = target_domain_size[1]\n",
    "        lower = (nb //2) - (na //2)\n",
    "        upper = (nb //2) + (na //2)\n",
    "\n",
    "        canvas[:,:,:, lower:upper] = img_resize\n",
    "\n",
    "\n",
    "    else:\n",
    "        factor = float(target_domain_size[1]) / img_shape_o[1]\n",
    "\n",
    "        target_height = int(factor*img_shape_o[0]) //2 *2\n",
    "        target_width = target_domain_size[1]\n",
    "\n",
    "        target_size = [target_height, target_width]\n",
    "        _img = _img.view(1,1,img_shape_o[0],img_shape_o[1])\n",
    "        img_resize = F.interpolate(_img, size=target_size, mode='bilinear',\n",
    "                                    align_corners=False)\n",
    "\n",
    "        na = target_height\n",
    "        nb = target_domain_size[0]\n",
    "        lower = (nb //2) - (na //2)\n",
    "        upper = (nb //2) + (na //2)\n",
    "\n",
    "        canvas[:,:,lower:upper, :] = img_resize\n",
    "\n",
    "    return canvas, factor, max_val\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def scipy_matfile_parse(filename):\n",
    "    '''\n",
    "    parse data from files and put them to GPU\n",
    "    Note that this function is for demo, and is different from the ones used in other places.\n",
    "    '''\n",
    "    data = sio.loadmat(filename)\n",
    "    depth0_np = data['depth']\n",
    "    seg0_np = data['seg']\n",
    "\n",
    "    ## change them to torch tensor\n",
    "    depth0 = torch.tensor(depth0_np, dtype=torch.float32, device=torch.device(\"cuda\"))\n",
    "    seg0 = torch.tensor(seg0_np, dtype=torch.float32, device=torch.device(\"cuda\"))\n",
    "\n",
    "    ## pre_processing\n",
    "    depth, factor_d,max_d = data_preprocessing(depth0, 'depth', target_domain_size=[128, 128])\n",
    "    seg, factor_s,_ = data_preprocessing(seg0, 'seg', target_domain_size=[128, 128])\n",
    "\n",
    "\n",
    "    cam_intrinsic_np = data['cam'][0][0]['intrinsic']\n",
    "    cam_intrinsic = torch.tensor(cam_intrinsic_np, dtype=torch.float32, device=torch.device(\"cuda\")).unsqueeze(0)\n",
    "    cam_extrinsic_np = data['cam'][0][0]['extrinsic']\n",
    "    cam_extrinsic_np = np.linalg.inv(cam_extrinsic_np)\n",
    "    cam_extrinsic = torch.tensor(cam_extrinsic_np, dtype=torch.float32, device=torch.device(\"cuda\")).unsqueeze(0)\n",
    "\n",
    "    return depth, seg, max_d.view(1), cam_intrinsic, cam_extrinsic\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) Prepare the scene without people\n",
    "\n",
    "Our method requires the following data about a scene:\n",
    "+ depth map\n",
    "+ semantic segmentation\n",
    "+ the camera parameters (extrinsic and intrinsic)\n",
    "+ the scene signed distance function (SDF)\n",
    "+ the scene mesh\n",
    "\n",
    "Note that SDF and scene mesh are only used for scene-geometry aware fitting. For generating body meshes with the CVAE model, only the first three attributes are sufficient.\n",
    "\n",
    "Here we use the 'MPH16' scene in the __PROXE__ dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenename = 'MPH16'\n",
    "proxe_path = '/data/proxe'\n",
    "\n",
    "## read the depth and semantics\n",
    "scene_matfile_path = os.path.join(proxe_path, 'snapshot_for_testing/MPH16_00157_01/rec_000000.mat')\n",
    "depth, seg, max_d, cam_intrinsic, cam_extrinsic = scipy_matfile_parse(scene_matfile_path)\n",
    "\n",
    "## read the sdf\n",
    "with open(os.path.join(proxe_path, 'scenes_sdf',scenename+'.json')) as f:\n",
    "    sdf_data = json.load(f)\n",
    "    grid_min = np.array(sdf_data['min'])\n",
    "    grid_max = np.array(sdf_data['max'])\n",
    "    grid_dim = sdf_data['dim']\n",
    "sdf = np.load(os.path.join(proxe_path, 'scenes_sdf', scenename + '_sdf.npy')).reshape(grid_dim, grid_dim, grid_dim)\n",
    "\n",
    "## read the scene mesh\n",
    "scene_mesh = o3d.io.read_triangle_mesh(os.path.join(proxe_path, 'scenes_downsampled', scenename+'.ply'))\n",
    "scene_verts = np.asarray(scene_mesh.vertices)\n",
    "scene_faces = np.asarray(scene_mesh.triangles)\n",
    "scene_pcd = PyntCloud.from_instance(\"open3d\", scene_mesh)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryeon/anaconda3/envs/psi/lib/python3.6/site-packages/pythreejs/traits.py:203: UserWarning: 64-bit data types not supported for WebGL data, casting to 32-bit.\n",
      "  warnings.warn('64-bit data types not supported for WebGL '\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e21d2b84b88e4a909767cd8ea3964eb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(camera=PerspectiveCamera(aspect=1.6, fov=90.0, position=(-0.38396479610201845, 2.714185747882214, 2.2…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5117eb0a2b54ca0ab8002a761b5f428",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='Point size:'), FloatSlider(value=0.5117690801620484, max=5.117690801620483, step=0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e6926a10825437a9b41e3338a47e0cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Preview(child=Scene(children=(Points(geometry=BufferGeometry(attributes={'position': <BufferAttribute shape=(5…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## We could visualize the scene data, or skip this step.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "depth_processed_np = depth.detach().cpu().squeeze().numpy()\n",
    "plt.imshow(depth_processed_np)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "seg_processed_np = seg.detach().cpu().squeeze().numpy()\n",
    "plt.imshow(seg_processed_np)\n",
    "\n",
    "# we use webGL to visualize 3D, which is a different case from running locally.\n",
    "# only works for point cloud visualization\n",
    "# note that visualizing 3D here may cause slow responses.\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = scene_mesh.vertices\n",
    "pcd.colors = scene_mesh.vertex_colors\n",
    "\n",
    "scene_pcd.plot(backend='pythreejs', return_scene=True)\n",
    "\n",
    "# from open3d import JVisualizer\n",
    "# visualizer = JVisualizer()\n",
    "# visualizer.add_geometry(pcd)\n",
    "# visualizer.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## （3） Generating body meshes using the pre-trained conditional VAE model\n",
    "\n",
    "For demonstration purposes, we only use the **one-stage model without scene loss**. For other models, the pipeline is the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Trained Model: /data/smpl_models/vposer_v1_0/snapshots/TR00_E096.pt\n",
      "[INFO] load checkpoints: checkpoints_v2/checkpoints_proxtrain_models1_batch32_epoch30_LR0.0003_LossVposer0.001_LossKL0.1_LossContact0.000001_LossCollision0.000001/epoch-000030.ckp\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testconfig={\n",
    "    'smplx_model_path': '/data/smpl_models',\n",
    "    'scene_model_ckpt': '/home/ryeon/project/psi/data/resnet18.pth',\n",
    "    'vposer_ckpt_path': '/data/smpl_models/vposer_v1_0',\n",
    "    'device': torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "    'ckpt_dir': 'checkpoints_v2/checkpoints_proxtrain_models1_batch32_epoch30_LR0.0003_LossVposer0.001_LossKL0.1_LossContact0.000001_LossCollision0.000001',\n",
    "    'n_samples': 2\n",
    "}\n",
    "\n",
    "### our conditional vae model\n",
    "model_h = HumanCVAES1(latentD=256, # default value in our checkpoints\n",
    "                      n_dim_body=75,# global T(3d) + global R(6d) + shape (10d) + pose (32d) + hand (24d)\n",
    "                      scene_model_ckpt=None,\n",
    "                      test=True)\n",
    "\n",
    "# model_h = HumanCVAES2(latentD_g=256, # default value in our checkpoints\n",
    "#                       latentD_l=256, # default value in our checkpoints\n",
    "#                       n_dim_body=75,# global T(3d) + global R(6d) + shape (10d) + pose (32d) + hand (24d)\n",
    "#                       scene_model_ckpt=None,\n",
    "#                       test=True)\n",
    "\n",
    "### VPoesr\n",
    "vposer, _ = load_vposer(testconfig['vposer_ckpt_path'], vp_model='snapshot')\n",
    "\n",
    "### smplx\n",
    "body_mesh_model = smplx.create(testconfig['smplx_model_path'], \n",
    "                               model_type='smplx',\n",
    "                               gender='neutral', ext='npz',\n",
    "                               num_pca_comps=12,\n",
    "                               create_global_orient=True,\n",
    "                               create_body_pose=True,\n",
    "                               create_betas=True,\n",
    "                               create_left_hand_pose=True,\n",
    "                               create_right_hand_pose=True,\n",
    "                               create_expression=True,\n",
    "                               create_jaw_pose=True,\n",
    "                               create_leye_pose=True,\n",
    "                               create_reye_pose=True,\n",
    "                               create_transl=True,\n",
    "                               batch_size=testconfig['n_samples']\n",
    "                               )\n",
    "\n",
    "## setup models and load checkpoints\n",
    "model_h.eval()\n",
    "model_h.to(testconfig['device'])\n",
    "\n",
    "vposer.to(testconfig['device'])\n",
    "body_mesh_model.to(testconfig['device'])\n",
    "\n",
    "ckp_path = sorted(glob.glob(os.path.join(testconfig['ckpt_dir'],'epoch-*.ckp')),\n",
    "                    key=os.path.getmtime)[-1]\n",
    "\n",
    "\n",
    "checkpoint = torch.load(ckp_path)\n",
    "print('[INFO] load checkpoints: ' + ckp_path)\n",
    "\n",
    "model_h.load_state_dict(checkpoint['model_h_state_dict'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following code block to sample body configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## generating body configurations\n",
    "\n",
    "### concatenate depth and seg\n",
    "xs = torch.cat([depth, seg],dim=1)\n",
    "xs_n = xs.repeat(testconfig['n_samples'], 1,1,1)\n",
    "\n",
    "### model inference\n",
    "xhnr_gen= model_h.sample(xs_n)\n",
    "\n",
    "### recover to the original translation/orientation range \n",
    "xhn_gen = convert_to_3D_rot(xhnr_gen)        \n",
    "xh_gen = recover_global_T(xhn_gen, cam_intrinsic.repeat(testconfig['n_samples'],1,1), \n",
    "                          max_d.repeat(testconfig['n_samples']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following, we visualize the generated body configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca8dec6175c9447986b2edb39d9c93c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(camera=PerspectiveCamera(aspect=1.6, fov=90.0, position=(-0.38396479610201845, 2.714185747882214, 2.2…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8074a714658e4e5e960ef8f17bdb4953",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='Point size:'), FloatSlider(value=0.1, max=1.0, step=0.001), Label(value='Backgroun…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8658dbaa88d34417928a01ecd7f7b0bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='Point size:'), FloatSlider(value=0.03, max=0.3, step=0.0003)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "931c6d24f85e46259cf31937cd4622e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='Point size:'), FloatSlider(value=0.03, max=0.3, step=0.0003)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## visualizing a body mesh. Note that we use WebGL, which may cause slow responses or even stuck.\n",
    "\n",
    "body_params = body_params_encapsulate(xh_gen, to_numpy=False, batched=True)\n",
    "body_params['body_pose'] = vposer.decode(body_params['body_pose'], output_type='aa').view(testconfig['n_samples'],-1)\n",
    "\n",
    "smplx_out = body_mesh_model(**body_params)\n",
    "smplx_verts = smplx_out.vertices.detach().cpu().numpy().squeeze()    \n",
    "\n",
    "cam_ext = cam_extrinsic.squeeze().detach().cpu().numpy()\n",
    "\n",
    "### create a body point cloud\n",
    "pcd_body_list = []\n",
    "for body_index in range(testconfig['n_samples']):\n",
    "    # body_index = 20\n",
    "    pcd_body = o3d.geometry.PointCloud()\n",
    "    pcd_body.points = o3d.utility.Vector3dVector(smplx_verts[body_index])\n",
    "    pcd_body = pcd_body.uniform_down_sample(every_k_points=2)\n",
    "    \n",
    "    ### perform transformation\n",
    "    pcd_body.transform(cam_ext)\n",
    "    pcd_body_list.append(pcd_body)\n",
    "    \n",
    "    \n",
    "\n",
    "### create a scene point cloud\n",
    "pcd_scene = o3d.geometry.PointCloud()\n",
    "pcd_scene.points = scene_mesh.vertices\n",
    "pcd_scene.colors = scene_mesh.vertex_colors\n",
    "pcd_scene = pcd_scene.uniform_down_sample(every_k_points=10)\n",
    "\n",
    "### create coord frame\n",
    "mesh_frame = o3d.geometry.TriangleMesh.create_coordinate_frame(\n",
    "        size=0.6, origin=[0, 0, 0])\n",
    "\n",
    "pcd_coord = o3d.geometry.PointCloud()\n",
    "pcd_coord.points = mesh_frame.vertices\n",
    "pcd_coord.colors = mesh_frame.vertex_colors\n",
    "pcd_coord.transform(cam_ext)\n",
    "\n",
    "#Visualize\n",
    "scene_pcd = PyntCloud.from_instance(\"open3d\", scene_mesh)\n",
    "tot_scene_pcd = scene_pcd.plot(backend='pythreejs', initial_point_size=0.1,  return_scene=True)\n",
    "\n",
    "import random\n",
    "colors = [157, 158, 204]\n",
    "\n",
    "for body_index in range(testconfig['n_samples']):\n",
    "    body_pcd = PyntCloud.from_instance(\"open3d\", pcd_body_list[body_index])\n",
    "    body_pcd.points[\"red\"] = random.choice(colors)\n",
    "    body_pcd.points[\"blue\"] = random.choice(colors)\n",
    "    body_pcd.points[\"green\"] = random.choice(colors)\n",
    "    body_pcd.plot(backend='pythreejs', initial_point_size=0.03, scene=tot_scene_pcd)\n",
    "\n",
    "    \n",
    "# ### visualize in WebGL\n",
    "# from open3d import JVisualizer\n",
    "# visualizer = JVisualizer()\n",
    "# visualizer.add_geometry(pcd_scene)\n",
    "# visualizer.add_geometry(pcd_coord)\n",
    "# for body_index in range(testconfig['n_samples']):\n",
    "#     visualizer.add_geometry(pcd_body_list[body_index])\n",
    "\n",
    "# visualizer.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4) scene geometry-aware fitting\n",
    "\n",
    "One see that some generated body meshes are not physically plausible, either floating in the air or penetrating into the scene mesh. Therefore, we have this geometry-aware fitting to overcome these problems. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO][fitting] iter=0, l_rec=0.000000, l_vposer=0.004256, l_contact=0.093401, l_collision=0.006423\n",
      "[INFO][fitting] iter=1, l_rec=0.044407, l_vposer=0.004221, l_contact=0.091316, l_collision=0.001594\n",
      "[INFO][fitting] iter=2, l_rec=0.020604, l_vposer=0.004237, l_contact=0.093899, l_collision=0.000699\n",
      "[INFO][fitting] iter=3, l_rec=0.030129, l_vposer=0.004285, l_contact=0.094715, l_collision=0.000681\n",
      "[INFO][fitting] iter=4, l_rec=0.037189, l_vposer=0.004288, l_contact=0.094620, l_collision=0.000227\n",
      "[INFO][fitting] iter=5, l_rec=0.033626, l_vposer=0.004258, l_contact=0.094839, l_collision=0.000427\n",
      "[INFO][fitting] iter=6, l_rec=0.023443, l_vposer=0.004217, l_contact=0.095018, l_collision=0.000342\n",
      "[INFO][fitting] iter=7, l_rec=0.013918, l_vposer=0.004193, l_contact=0.095003, l_collision=0.000756\n",
      "[INFO][fitting] iter=8, l_rec=0.020495, l_vposer=0.004207, l_contact=0.094590, l_collision=0.000491\n",
      "[INFO][fitting] iter=9, l_rec=0.023386, l_vposer=0.004228, l_contact=0.094163, l_collision=0.000420\n",
      "[INFO][fitting] iter=10, l_rec=0.021098, l_vposer=0.004248, l_contact=0.093938, l_collision=0.000654\n",
      "[INFO][fitting] iter=11, l_rec=0.019800, l_vposer=0.004284, l_contact=0.093566, l_collision=0.000992\n",
      "[INFO][fitting] iter=12, l_rec=0.018824, l_vposer=0.004299, l_contact=0.092866, l_collision=0.001159\n",
      "[INFO][fitting] iter=13, l_rec=0.014633, l_vposer=0.004291, l_contact=0.091829, l_collision=0.001013\n",
      "[INFO][fitting] iter=14, l_rec=0.012605, l_vposer=0.004259, l_contact=0.091222, l_collision=0.000744\n",
      "[INFO][fitting] iter=15, l_rec=0.015357, l_vposer=0.004230, l_contact=0.090979, l_collision=0.000672\n",
      "[INFO][fitting] iter=16, l_rec=0.016730, l_vposer=0.004216, l_contact=0.090915, l_collision=0.000681\n",
      "[INFO][fitting] iter=17, l_rec=0.016664, l_vposer=0.004224, l_contact=0.090680, l_collision=0.000764\n",
      "[INFO][fitting] iter=18, l_rec=0.013927, l_vposer=0.004222, l_contact=0.090553, l_collision=0.000917\n",
      "[INFO][fitting] iter=19, l_rec=0.010761, l_vposer=0.004234, l_contact=0.090595, l_collision=0.001004\n",
      "[INFO][fitting] iter=20, l_rec=0.013148, l_vposer=0.004245, l_contact=0.090540, l_collision=0.000913\n",
      "[INFO][fitting] iter=21, l_rec=0.014328, l_vposer=0.004258, l_contact=0.090584, l_collision=0.000757\n",
      "[INFO][fitting] iter=22, l_rec=0.013682, l_vposer=0.004266, l_contact=0.090472, l_collision=0.000652\n",
      "[INFO][fitting] iter=23, l_rec=0.014060, l_vposer=0.004276, l_contact=0.090512, l_collision=0.000671\n",
      "[INFO][fitting] iter=24, l_rec=0.013186, l_vposer=0.004271, l_contact=0.090526, l_collision=0.000719\n",
      "[INFO][fitting] iter=25, l_rec=0.010997, l_vposer=0.004261, l_contact=0.090669, l_collision=0.000758\n",
      "[INFO][fitting] iter=26, l_rec=0.010838, l_vposer=0.004254, l_contact=0.090784, l_collision=0.000739\n",
      "[INFO][fitting] iter=27, l_rec=0.011935, l_vposer=0.004254, l_contact=0.090833, l_collision=0.000894\n",
      "[INFO][fitting] iter=28, l_rec=0.012701, l_vposer=0.004257, l_contact=0.090837, l_collision=0.001019\n",
      "[INFO][fitting] iter=29, l_rec=0.012155, l_vposer=0.004258, l_contact=0.090844, l_collision=0.000948\n",
      "[INFO][fitting] iter=30, l_rec=0.010170, l_vposer=0.004257, l_contact=0.090905, l_collision=0.000850\n",
      "[INFO][fitting] iter=31, l_rec=0.009087, l_vposer=0.004249, l_contact=0.091036, l_collision=0.000787\n",
      "[INFO][fitting] iter=32, l_rec=0.010301, l_vposer=0.004251, l_contact=0.091116, l_collision=0.000772\n",
      "[INFO][fitting] iter=33, l_rec=0.011050, l_vposer=0.004251, l_contact=0.091317, l_collision=0.000831\n",
      "[INFO][fitting] iter=34, l_rec=0.010481, l_vposer=0.004254, l_contact=0.091067, l_collision=0.000732\n",
      "[INFO][fitting] iter=35, l_rec=0.010934, l_vposer=0.004245, l_contact=0.091062, l_collision=0.000623\n",
      "[INFO][fitting] iter=36, l_rec=0.010492, l_vposer=0.004235, l_contact=0.091031, l_collision=0.000589\n",
      "[INFO][fitting] iter=37, l_rec=0.009361, l_vposer=0.004228, l_contact=0.090937, l_collision=0.000581\n",
      "[INFO][fitting] iter=38, l_rec=0.009773, l_vposer=0.004233, l_contact=0.090938, l_collision=0.000569\n",
      "[INFO][fitting] iter=39, l_rec=0.010882, l_vposer=0.004256, l_contact=0.090727, l_collision=0.000520\n",
      "[INFO][fitting] iter=40, l_rec=0.011066, l_vposer=0.004272, l_contact=0.090727, l_collision=0.000503\n",
      "[INFO][fitting] iter=41, l_rec=0.010890, l_vposer=0.004277, l_contact=0.090695, l_collision=0.000562\n",
      "[INFO][fitting] iter=42, l_rec=0.009620, l_vposer=0.004266, l_contact=0.090755, l_collision=0.000729\n",
      "[INFO][fitting] iter=43, l_rec=0.008658, l_vposer=0.004261, l_contact=0.090775, l_collision=0.000784\n",
      "[INFO][fitting] iter=44, l_rec=0.009797, l_vposer=0.004250, l_contact=0.090873, l_collision=0.000696\n",
      "[INFO][fitting] iter=45, l_rec=0.010438, l_vposer=0.004244, l_contact=0.091073, l_collision=0.000605\n",
      "[INFO][fitting] iter=46, l_rec=0.010568, l_vposer=0.004247, l_contact=0.091121, l_collision=0.000633\n",
      "[INFO][fitting] iter=47, l_rec=0.010386, l_vposer=0.004257, l_contact=0.091068, l_collision=0.000717\n",
      "[INFO][fitting] iter=48, l_rec=0.010115, l_vposer=0.004270, l_contact=0.091042, l_collision=0.000843\n",
      "[INFO][fitting] iter=49, l_rec=0.009475, l_vposer=0.004274, l_contact=0.091011, l_collision=0.000735\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import chamfer_pytorch.dist_chamfer as ext\n",
    "\n",
    "\n",
    "def get_contact_id(body_segments_folder, contact_body_parts=['L_Hand', 'R_Hand']):\n",
    "\n",
    "    contact_verts_ids = []\n",
    "    contact_faces_ids = []\n",
    "\n",
    "    for part in contact_body_parts:\n",
    "        with open(os.path.join(body_segments_folder, part + '.json'), 'r') as f:\n",
    "            data = json.load(f)\n",
    "            contact_verts_ids.append(list(set(data[\"verts_ind\"])))\n",
    "            contact_faces_ids.append(list(set(data[\"faces_ind\"])))\n",
    "\n",
    "    contact_verts_ids = np.concatenate(contact_verts_ids)\n",
    "    contact_faces_ids = np.concatenate(contact_faces_ids)\n",
    "\n",
    "\n",
    "    return contact_verts_ids, contact_faces_ids\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "def verts_transform(verts_batch, cam_ext_batch):\n",
    "    verts_batch_homo = F.pad(verts_batch, (0,1), mode='constant', value=1)\n",
    "    verts_batch_homo_transformed = torch.matmul(verts_batch_homo,\n",
    "                                                cam_ext_batch.permute(0,2,1))\n",
    "\n",
    "    verts_batch_transformed = verts_batch_homo_transformed[:,:,:-1]\n",
    "    \n",
    "    return verts_batch_transformed    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "def cal_loss(xhr, xhr_rec, cam_ext_batch, s_verts_batch,\n",
    "             s_sdf_batch,s_grid_min_batch, s_grid_max_batch,\n",
    "             lossconfig, fittingconfig):\n",
    "\n",
    "\n",
    "    ### reconstruction loss\n",
    "    loss_rec = lossconfig['weight_loss_rec']*F.l1_loss(xhr, xhr_rec)\n",
    "    xh_rec = convert_to_3D_rot(xhr_rec)\n",
    "\n",
    "    ### vposer loss\n",
    "    vposer_pose = xh_rec[:,16:48]\n",
    "    loss_vposer = lossconfig['weight_loss_vposer'] * torch.mean(vposer_pose**2)\n",
    "\n",
    "    ### contact loss\n",
    "    body_param_rec = body_params_encapsulate(xh_rec, to_numpy=False, batched=True)\n",
    "    body_param_rec['body_pose'] = vposer.decode(body_param_rec['body_pose'], \n",
    "                                       output_type='aa').view(xhr.shape[0], -1)\n",
    "\n",
    "    smplx_output = body_mesh_model(return_verts=True, **body_param_rec)\n",
    "    body_verts_batch = smplx_output.vertices #[b, 10475,3]\n",
    "    body_verts_batch = verts_transform(body_verts_batch, cam_ext_batch)\n",
    "\n",
    "    \n",
    "    vid, fid = get_contact_id(body_segments_folder=fittingconfig['body_segments_folder'],\n",
    "                              contact_body_parts=fittingconfig['contact_part'])\n",
    "    \n",
    "    body_verts_contact_batch = body_verts_batch[:, vid, :]\n",
    "\n",
    "    dist_chamfer_contact = ext.chamferDist()\n",
    "    contact_dist, _ = dist_chamfer_contact(body_verts_contact_batch.contiguous(), \n",
    "                                            s_verts_batch.contiguous())\n",
    "\n",
    "    loss_contact = lossconfig['weight_contact'] * torch.mean(torch.sqrt(contact_dist+1e-4)\n",
    "                                                            /(torch.sqrt(contact_dist+1e-4)+0.01))  \n",
    "\n",
    "\n",
    "\n",
    "    ### sdf collision loss\n",
    "    s_grid_min_batch = s_grid_min_batch.unsqueeze(1)\n",
    "    s_grid_max_batch = s_grid_max_batch.unsqueeze(1)\n",
    "\n",
    "    norm_verts_batch = (body_verts_batch - s_grid_min_batch) / (s_grid_max_batch - s_grid_min_batch) *2 -1\n",
    "    n_verts = norm_verts_batch.shape[1]\n",
    "    body_sdf_batch = F.grid_sample(s_sdf_batch.unsqueeze(1), \n",
    "                                    norm_verts_batch[:,:,[2,1,0]].view(-1, n_verts,1,1,3),\n",
    "                                    padding_mode='border')\n",
    "\n",
    "\n",
    "    # if there are no penetrating vertices then set sdf_penetration_loss = 0\n",
    "    if body_sdf_batch.lt(0).sum().item() < 1:\n",
    "        loss_sdf_pene = torch.tensor(0.0, dtype=torch.float32, device=self.device)\n",
    "    else:\n",
    "        loss_sdf_pene = body_sdf_batch[body_sdf_batch < 0].abs().mean()\n",
    "\n",
    "    loss_collision = lossconfig['weight_collision']*loss_sdf_pene\n",
    "\n",
    "    return loss_rec, loss_vposer, loss_contact, loss_collision\n",
    "\n",
    " \n",
    "    \n",
    "def fitting(xhr_in, cam_extrinsic,\n",
    "            s_verts, s_sdf, s_grid_min, s_grid_max, max_d,\n",
    "            fittingconfig, lossconfig):\n",
    "    \n",
    "    \n",
    "    batch_size = xhr_in.shape[0]\n",
    "    xhr_rec = Variable(torch.randn(batch_size,75).cuda(), requires_grad=True)\n",
    "    optimizer = optim.Adam([xhr_rec], lr=fittingconfig['init_lr_h'])\n",
    "    xhr_rec.data = xhr_in.clone()\n",
    "\n",
    "    \n",
    "    cam_ext_batch = cam_extrinsic.repeat(batch_size, 1,1)\n",
    "    max_d_batch = max_d.repeat(batch_size)\n",
    "    s_verts_batch = s_verts.repeat(batch_size, 1,1)\n",
    "    s_sdf_batch = s_sdf.repeat(batch_size, 1,1,1)\n",
    "    s_grid_min_batch = s_grid_min.repeat(batch_size, 1)\n",
    "    s_grid_max_batch = s_grid_max.repeat(batch_size, 1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    for ii in range(fittingconfig['num_iter']):\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss_rec, loss_vposer, loss_contact, loss_collision = cal_loss(xhr_in, xhr_rec, cam_ext_batch, s_verts_batch,\n",
    "                                                                         s_sdf_batch,s_grid_min_batch, s_grid_max_batch,\n",
    "                                                                         lossconfig, fittingconfig)\n",
    "        loss = loss_rec + loss_vposer + loss_contact + loss_collision\n",
    "        if fittingconfig['verbose']:\n",
    "            print('[INFO][fitting] iter={:d}, l_rec={:f}, l_vposer={:f}, l_contact={:f}, l_collision={:f}'.format(\n",
    "                                    ii, loss_rec.item(), loss_vposer.item(), \n",
    "                                    loss_contact.item(), loss_collision.item()) )\n",
    "\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "\n",
    "    ### recover global translation and orientation\n",
    "    xh_rec = convert_to_3D_rot(xhr_rec)        \n",
    "\n",
    "    return xh_rec\n",
    "    \n",
    "    \n",
    "    \n",
    "fittingconfig={'init_lr_h': 0.05,\n",
    "                'num_iter': 50, \n",
    "                'contact_part': ['back','butt','L_Hand','R_Hand','L_Leg',\n",
    "                                 'R_Leg','thighs'],\n",
    "                'body_segments_folder': os.path.join(proxe_path,'body_segments'),\n",
    "                'verbose': True\n",
    "              }\n",
    "\n",
    "lossconfig={\n",
    "    'weight_loss_rec': 1,\n",
    "    'weight_loss_vposer':0.01,\n",
    "    'weight_contact': 0.1,\n",
    "    'weight_collision' : 0.5\n",
    "}\n",
    "\n",
    "\n",
    "### put scene to tensors\n",
    "s_verts = torch.tensor(scene_verts, dtype=torch.float32).cuda().unsqueeze(0)\n",
    "s_grid_min = torch.tensor(grid_min, dtype=torch.float32).cuda().unsqueeze(0)\n",
    "s_grid_max = torch.tensor(grid_max, dtype=torch.float32).cuda().unsqueeze(0)\n",
    "s_sdf = torch.tensor(sdf, dtype=torch.float32).cuda().unsqueeze(0)        \n",
    "        \n",
    "xhr_gen = recover_global_T(xhnr_gen, cam_intrinsic.repeat(testconfig['n_samples'],1,1), \n",
    "                          max_d.repeat(testconfig['n_samples']))\n",
    "\n",
    "xh_fitting = fitting(xhr_gen, cam_extrinsic,\n",
    "                    s_verts, s_sdf, s_grid_min, s_grid_max, max_d,\n",
    "                    fittingconfig, lossconfig)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1caa87205d684ea7b27cc5e735aae1e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(camera=PerspectiveCamera(aspect=1.6, fov=90.0, position=(-0.38396479610201845, 2.714185747882214, 2.2…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67fda2c6d4ce4b2184b102a815d7f098",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='Point size:'), FloatSlider(value=0.1, max=1.0, step=0.001), Label(value='Backgroun…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59f0651bb0434b6098bb176ee1d8f9f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='Point size:'), FloatSlider(value=0.03, max=0.3, step=0.0003)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e8ea5dc8c6d499eb0d9a7602f61c72f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='Point size:'), FloatSlider(value=0.03, max=0.3, step=0.0003)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## visualizing a body mesh. Note that we use WebGL, which may cause slow responses or even stuck.\n",
    "\n",
    "body_params = body_params_encapsulate(xh_fitting, to_numpy=False, batched=True)\n",
    "body_params['body_pose'] = vposer.decode(body_params['body_pose'], output_type='aa').view(testconfig['n_samples'],-1)\n",
    "\n",
    "smplx_out = body_mesh_model(**body_params)\n",
    "smplx_verts = smplx_out.vertices.detach().cpu().numpy().squeeze()    \n",
    "\n",
    "cam_ext = cam_extrinsic.squeeze().detach().cpu().numpy()\n",
    "\n",
    "### create a body point cloud\n",
    "pcd_body_list = []\n",
    "for body_index in range(testconfig['n_samples']):\n",
    "    # body_index = 20\n",
    "    pcd_body = o3d.geometry.PointCloud()\n",
    "    pcd_body.points = o3d.utility.Vector3dVector(smplx_verts[body_index])\n",
    "    pcd_body = pcd_body.uniform_down_sample(every_k_points=2)\n",
    "    \n",
    "    ### perform transformation\n",
    "    pcd_body.transform(cam_ext)\n",
    "    pcd_body_list.append(pcd_body)\n",
    "    \n",
    "    \n",
    "\n",
    "### create a scene point cloud\n",
    "pcd_scene = o3d.geometry.PointCloud()\n",
    "pcd_scene.points = scene_mesh.vertices\n",
    "pcd_scene.colors = scene_mesh.vertex_colors\n",
    "pcd_scene = pcd_scene.uniform_down_sample(every_k_points=10)\n",
    "\n",
    "### create coord frame\n",
    "mesh_frame = o3d.geometry.TriangleMesh.create_coordinate_frame(\n",
    "        size=0.6, origin=[0, 0, 0])\n",
    "\n",
    "pcd_coord = o3d.geometry.PointCloud()\n",
    "pcd_coord.points = mesh_frame.vertices\n",
    "pcd_coord.colors = mesh_frame.vertex_colors\n",
    "pcd_coord.transform(cam_ext)\n",
    "\n",
    "#Visualize\n",
    "scene_pcd = PyntCloud.from_instance(\"open3d\", scene_mesh)\n",
    "tot_scene_pcd = scene_pcd.plot(backend='pythreejs', initial_point_size=0.1,  return_scene=True)\n",
    "    \n",
    "for body_index in range(testconfig['n_samples']):\n",
    "    body_pcd = PyntCloud.from_instance(\"open3d\", pcd_body_list[body_index])\n",
    "    body_pcd.points[\"red\"] = random.choice(colors)\n",
    "    body_pcd.points[\"blue\"] = random.choice(colors)\n",
    "    body_pcd.points[\"green\"] = random.choice(colors)\n",
    "    body_pcd.plot(backend='pythreejs', initial_point_size=0.03, scene=tot_scene_pcd) \n",
    "\n",
    "### visualize in WebGL\n",
    "# from open3d import JVisualizer\n",
    "# visualizer = JVisualizer()\n",
    "# visualizer.add_geometry(pcd_scene)\n",
    "# visualizer.add_geometry(pcd_coord)\n",
    "\n",
    "# for body_index in range(testconfig['n_samples']):\n",
    "#     visualizer.add_geometry(pcd_body_list[body_index])\n",
    "\n",
    "# visualizer.show()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}